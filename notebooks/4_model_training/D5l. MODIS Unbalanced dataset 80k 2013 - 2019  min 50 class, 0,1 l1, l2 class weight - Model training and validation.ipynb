{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D5l. MODIS Unbalanced dataset 80k 2013 - 2019  min 50 class, 0,1 l1, l2- Model training and validation :\n",
    "This model will use data obtained from MODIS (one day only), NDWI, NDWI_ICE, DEM SLOPE and EUCLIDEAN_NORM to predict water and non-water features. For all years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Load required libraries, site dependant constants and utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "# EOLearn libraries:\n",
    "from eolearn.core import EOTask, EOPatch, LinearWorkflow, LoadTask, SaveTask, FeatureType, EOExecutor\n",
    "from eolearn.core import OverwritePermission\n",
    "\n",
    "# Add to python path parent dictionary\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# load site dependant constants (HERE YOU CAN CHOOSE DIFFERENT LOCATION)\n",
    "from aoi_sites import upe_promice_area as site\n",
    "\n",
    "# load utility functions\n",
    "from utils import io_functions as io_utils\n",
    "from utils import plot_functions as plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load sampled eopatches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick dataset_name\n",
    "input_dataset_file_name = '_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/'\n",
    "\n",
    "dataset_filepath_2013 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2013_05-2013_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2014 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2014_05-2014_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2015 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2015_05-2015_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2016 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2016_05-2016_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2017 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2017_05-2017_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2018 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2018_05-2018_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2019 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2019_05-2019_10{}'.format(input_dataset_file_name)\n",
    "\n",
    "dataset_path_list = [dataset_filepath_2013,\n",
    "                dataset_filepath_2014,\n",
    "                dataset_filepath_2015,\n",
    "                dataset_filepath_2016,\n",
    "                dataset_filepath_2017,\n",
    "                dataset_filepath_2018,\n",
    "                dataset_filepath_2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Choose test eopatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_available_patches_2013 = io_utils.get_list_of_eopatches(dataset_filepath_2013)\n",
    "\n",
    "#test_eppatches_chosen_names = np.random.choice(list_of_available_patches_2013, 7, replace=True)\n",
    "#test_eppatches_chosen_names\n",
    "\n",
    "test_eppatches_chosen_names = np.array(['2974_maxcc_0.05_x-3_y-135', '2976_maxcc_0.05_x-3_y-137',\n",
    "       '3179_maxcc_0.05_x-5_y-137', '3067_maxcc_0.05_x-4_y-138',\n",
    "       '3180_maxcc_0.05_x-5_y-138', '3473_maxcc_0.05_x-7_y-134',\n",
    "       '2975_maxcc_0.05_x-3_y-136'], dtype='<U25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n",
      "46\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eopatches= []\n",
    "test_eopatches= []\n",
    "train_eopatches_filenames = []\n",
    "test_eopatches_filenames = []\n",
    "\n",
    "for eopatches_filepath in dataset_path_list:\n",
    "\n",
    "    list_of_available_patches = io_utils.get_list_of_eopatches(eopatches_filepath)\n",
    "    list_in_chunks = io_utils.chunkIt(list_of_available_patches, 2 ) # number of chunks- 1 bc all can go\n",
    "    for chunk in list_in_chunks:\n",
    "        #print('Doing now following eopatches:', chunk )\n",
    "        for eopatch_name in chunk:\n",
    "            if eopatch_name in test_eppatches_chosen_names:\n",
    "                test_eopatches_filenames.append(eopatches_filepath+eopatch_name)\n",
    "                test_eopatches.append(EOPatch.load(eopatches_filepath+eopatch_name, lazy_loading=True))\n",
    "                \n",
    "            else:\n",
    "                train_eopatches_filenames.append(eopatches_filepath+eopatch_name)\n",
    "                train_eopatches.append(EOPatch.load(eopatches_filepath+eopatch_name, lazy_loading=True))    \n",
    "print(len(train_eopatches))\n",
    "print(len(test_eopatches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2013_05-2013_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/2974_maxcc_0.05_x-3_y-135',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2013_05-2013_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/2975_maxcc_0.05_x-3_y-136',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2013_05-2013_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/3179_maxcc_0.05_x-5_y-137',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2013_05-2013_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/3180_maxcc_0.05_x-5_y-138',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2013_05-2013_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/3473_maxcc_0.05_x-7_y-134',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2014_05-2014_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/2974_maxcc_0.05_x-3_y-135',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2014_05-2014_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/2975_maxcc_0.05_x-3_y-136',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2014_05-2014_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/2976_maxcc_0.05_x-3_y-137',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2014_05-2014_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/3067_maxcc_0.05_x-4_y-138',\n",
       " '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2014_05-2014_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/3179_maxcc_0.05_x-5_y-137']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all eopatches from all years are there. \n",
    "test_eopatches_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from ../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2019_05-2019_10_sptl_smpl_80000_pr_pic_ref_0_1_min_wat_25/3069_maxcc_0.05_x-4_y-140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    DATASET_RAW_NDWI_NRB_19_NORM_SLOPE_SAMPLED: numpy.ndarray(shape=(13, 80000, 1, 13), dtype=float32)\n",
       "  }\n",
       "  mask: {\n",
       "    WATER_MASK_ST_025_SAMPLED: numpy.ndarray(shape=(13, 80000, 1, 1), dtype=bool)\n",
       "  }\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {}\n",
       "  mask_timeless: {}\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {\n",
       "    DEM_RAW_AVG: 1200.0557\n",
       "    DEM_RAW_MAX: 1303.0\n",
       "    DEM_RAW_MED: 1200.0\n",
       "    DEM_RAW_MIN: 1089.0\n",
       "    DEM_RAW_STD: 39.861797\n",
       "    DEM_RAW_VAR: 1588.9629\n",
       "    index_x: 4\n",
       "    index_y: 140\n",
       "    maxcc: '0.05'\n",
       "    patch_index: 3069\n",
       "    service_type: 'wcs'\n",
       "    site_name: 'UPE_PROMICE'\n",
       "    size_x: '30m'\n",
       "    size_y: '30m'\n",
       "    time_difference: datetime.timedelta(seconds=7200)\n",
       "    time_interval: ('2019-05-01', '2019-10-31')\n",
       "  }\n",
       "  bbox: BBox(((410000.0, 8130000.0), (420000.0, 8140000.0)), crs=EPSG:32622)\n",
       "  timestamp: [datetime.datetime(2019, 7, 1, 0, 1, 24), ..., datetime.datetime(2019, 8, 28, 15, 36, 41)], length=13\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eo_patch = io_utils.load_exemplary_eopatch_from_file(file ='../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2019_05-2019_10{}'.format(input_dataset_file_name))\n",
    "eo_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3. Fetch and organise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the train and test patch IDs\n",
    "\n",
    "# Set the features and the labels for train and test sets\n",
    "features_train = np.array([eopatch.data['DATASET_RAW_NDWI_NRB_19_NORM_SLOPE_SAMPLED'] for eopatch in train_eopatches if eopatch.data['DATASET_RAW_NDWI_NRB_19_NORM_SLOPE_SAMPLED'].size > 0])\n",
    "#features_train (number_of_patches,(time,width,height, bands))\n",
    "labels_train = np.array([eopatch.mask['WATER_MASK_ST_025_SAMPLED'] for eopatch in train_eopatches if eopatch.mask['WATER_MASK_ST_025_SAMPLED'].size > 0])\n",
    "#features_train (number_of_patches,(time,width,height, answer=True, False))\n",
    "features_test = np.array([eopatch.data['DATASET_RAW_NDWI_NRB_19_NORM_SLOPE_SAMPLED'] for eopatch in test_eopatches if eopatch.data['DATASET_RAW_NDWI_NRB_19_NORM_SLOPE_SAMPLED'].size > 0 ])\n",
    "labels_test = np.array([eopatch.mask['WATER_MASK_ST_025_SAMPLED'] for eopatch in test_eopatches if eopatch.mask['WATER_MASK_ST_025_SAMPLED'].size > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to  (number_of_patches x time, width, height, bands)\n",
    "features_train_stacked = np.vstack(features_train)\n",
    "labels_train_stacked = np.vstack(labels_train)\n",
    "features_test_stacked = np.vstack(features_test)\n",
    "labels_test_stacked = np.vstack(labels_test)\n",
    "\n",
    "# get shape\n",
    "p_train_x_time, w, h, b = features_train_stacked.shape\n",
    "p_test_x_time, w, h, b = features_test_stacked.shape\n",
    "\n",
    "\n",
    "# reshape to n x m\n",
    "#n - no of observation\n",
    "#m - no of features, - bands in my case, misssing DEM\n",
    "\n",
    "features_train = features_train_stacked.reshape(p_train_x_time * w * h, b)\n",
    "labels_train = labels_train_stacked.reshape(p_train_x_time * w * h, 1)\n",
    "features_test = features_test_stacked.reshape(p_test_x_time * w * h, b)\n",
    "labels_test = labels_test_stacked.reshape(p_test_x_time * w * h, 1)\n",
    "\n",
    "\n",
    "#@TODO\n",
    "# remove points with no reference from training (so we dont train to recognize \"no data\")\n",
    "# interpolation????\n",
    "#mask_train = labels_train == 0\n",
    "#features_train = features_train[~mask_train]\n",
    "#labels_train = labels_train[~mask_train]\n",
    "\n",
    "# remove points with no reference from test (so we dont validate on \"no data\", which doesn't make sense)\n",
    "#mask_test = labels_test == 0\n",
    "#features_test = features_test[~mask_test]\n",
    "#labels_test = labels_test[~mask_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  5. Pickle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-fb9123f53fe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "dataset = [features_train, labels_train, features_test, labels_test ]\n",
    "dataset_name = 'dataset_2013_05-2019_10_sptl_smpl_80k_pr_patch_balanced_classes_1_2_min_25_test_7_test_fixed'\n",
    "\n",
    "with open('{}.pickle'.format(dataset_name), 'wb') as output:\n",
    "    pickle.dump(dataset, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to compare old data distribution (little less )\n",
    "\n",
    "print('TRAIN DATA:')\n",
    "tot_obs = np.size(labels_train)\n",
    "print('Total observations: ', tot_obs )\n",
    "\n",
    "tot_wat = np.count_nonzero(labels_train)\n",
    "print('Total water count', tot_wat )\n",
    "\n",
    "ratio_wat_vs_non_wat = tot_wat/ tot_obs\n",
    "print('Percent of water feature among data:', ratio_wat_vs_non_wat )\n",
    "\n",
    "print('\\nTEST DATA:')\n",
    "\n",
    "tot_obs = np.size(labels_test)\n",
    "print('Total observations: ', tot_obs )\n",
    "\n",
    "tot_wat = np.count_nonzero(labels_test)\n",
    "print('Total water count', tot_wat )\n",
    "\n",
    "ratio_wat_vs_non_wat = tot_wat/ tot_obs\n",
    "print('Percent of water feature among data:', ratio_wat_vs_non_wat )\n",
    "# dataset is half of the previous one!!!\n",
    "\n",
    "sample_pos_weight = (tot_obs - tot_wat ) / tot_wat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train.squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set up training classes\n",
    "labels_unique = np.unique(labels_train)\n",
    "\n",
    "# Set up the model\n",
    "model = LGBMClassifier(boosting='gbdt',\n",
    "    objective='binary',\n",
    "    learning_rate=0.1,\n",
    "    metric='mse', #mae: mean absolute error mse: mean squared error\n",
    "    scale_pos_weight= sample_pos_weight/10, # add a weight to the positive class examples.\n",
    "    # this can account for highly skewed data.\n",
    "    #class_weight= 'balanced' \n",
    "    lambda_l1   = 0.5, # L1 regularization.\n",
    "    lambda_l2   = 0.5, # L2 regularization.\n",
    "    max_depth = 6,\n",
    "    num_leaves = 40\n",
    "            \n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(features_train, labels_train.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "_ = lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lgb.plot_tree(model, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to save the model\n",
    "model_base_name = 'NEW_model_20000_unbalanced_WATER_only_MODIS_test_7_fixed_lr_01_min_wat_50_scale_pos_class_l1_l2'\n",
    "joblib.dump(model, './{}.pkl'.format(model_base_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  5. Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TEST:')\n",
    "# predict the test labels\n",
    "plabels_test = model.predict(features_test)\n",
    "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_test, plabels_test)))\n",
    "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_test, plabels_test, average='weighted')))\n",
    "\n",
    "# predict the train labels\n",
    "plabels_train = model.predict(features_train)\n",
    "print('TRAIN:')\n",
    "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_train, plabels_train)))\n",
    "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_train, plabels_train, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_water = np.count_nonzero(labels_test)\n",
    "predicted_water = np.count_nonzero(plabels_test)\n",
    "\n",
    "print('Water Test data size:',actual_water)\n",
    "\n",
    "tp = np.count_nonzero(np.logical_and(labels_test.squeeze(), plabels_test.squeeze()))\n",
    "print('Water True positive:', tp, 'and recall', 100* tp /actual_water, 'and precision:', tp /predicted_water)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.unique(labels_test)\n",
    "print(class_labels)\n",
    "class_names = ['non-water', 'water']\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_scores = metrics.f1_score(labels_test, plabels_test, labels=class_labels, average=None)\n",
    "recall = metrics.recall_score(labels_test, plabels_test, labels=class_labels, average=None)\n",
    "precision = metrics.precision_score(labels_test, plabels_test, labels=class_labels, average=None) \n",
    "\n",
    "print('             Class              =  F1  | Recall | Precision')\n",
    "print('         --------------------------------------------------')\n",
    "for idx, lulctype in enumerate([class_names[idx] for idx in class_labels]):\n",
    "    print('         * {0:20s} = {1:2.1f}% |  {2:2.1f}%  | {3:2.1f}%'.format(lulctype, \n",
    "                                                                         f1_scores[idx] * 100, \n",
    "                                                                         recall[idx] * 100, \n",
    "                                                                         precision[idx] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Plot the standard and transposed Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "# Define the plotting function\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues, ylabel='True label', xlabel='Predicted label', filename=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + np.finfo(np.float).eps)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.title(title, fontsize=20)\n",
    "    # plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize=20)\n",
    "    plt.yticks(tick_marks, classes, fontsize=20)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(ylabel, fontsize=20)\n",
    "    plt.xlabel(xlabel, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "conf_matrix_gbm = metrics.confusion_matrix(labels_test, plabels_test)\n",
    "plot_confusion_matrix(conf_matrix_gbm, \n",
    "                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n",
    "                      normalize=True, \n",
    "                      ylabel='Ground Truth', \n",
    "                      xlabel='Predicted Labels',\n",
    "                      title='Confusion matrix');\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "conf_matrix_gbm = metrics.confusion_matrix(plabels_test, labels_test)\n",
    "plot_confusion_matrix(conf_matrix_gbm, \n",
    "                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n",
    "                      normalize=True, \n",
    "                      xlabel='Ground Truth', \n",
    "                      ylabel='Predicted Labels',\n",
    "                      title='Transposed Confusion matrix');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Plot dataset balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "label_ids, label_counts = np.unique(labels_train, return_counts=True)\n",
    "\n",
    "plt.bar(range(len(label_ids)), label_counts)\n",
    "plt.xticks(range(len(label_ids)), [class_names[i] for i in label_ids], rotation=45, fontsize=20);\n",
    "plt.yticks(fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. ROC curves and AUC metrics\n",
    "Calculate precision and recall rates, draw ROC curves and calculate AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels_zero_one = 1*class_labels\n",
    "l_one_zero = 1*labels_test\n",
    "l_one_zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scores_test = model.predict_proba(features_test)\n",
    "\n",
    "labels_binarized = preprocessing.label_binarize((1*labels_test).tolist(), classes=[0, 1, 3])\n",
    "labels_binarized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for idx,lbl in enumerate([1, 2]):\n",
    "    fpr[idx], tpr[idx], _ = metrics.roc_curve(labels_binarized[:, idx], scores_test[:, idx])\n",
    "    roc_auc[idx] = metrics.auc(fpr[idx], tpr[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for idx,lbl in enumerate(class_labels):\n",
    "    if np.isnan(roc_auc[idx]):\n",
    "        continue\n",
    "    plt.plot(fpr[idx], tpr[idx],\n",
    "         lw=2, label=class_names[lbl] + ' (%0.5f)' % roc_auc[idx])\n",
    "    \n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 0.99])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.title('ROC Curve', fontsize=20)\n",
    "plt.legend(loc=\"center right\", prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Most important features:\n",
    "Let us now check which features are most important in the above classification. The LightGBM model already contains the information about feature importances, so we only need to query them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of features\n",
    "fnames = ['B01_RED', 'B02_NIR', 'B03_BLUE', 'B04_GREEN', 'B05_NIR-2', 'B06_SWIR', 'B07_SWIR-2', 'NDWI', 'NDWI_AVG','NDWI_VAR', 'EUC_NORM','NDWI_ICE', 'DEM_SLOPE', ]\n",
    "\n",
    "# get feature importances and reshape them to dates and features\n",
    "z = model.feature_importances_.reshape((1, b))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = plt.gca()\n",
    "\n",
    "# plot the importances\n",
    "im = ax.imshow(z, aspect=0.25)\n",
    "plt.xticks(range(len(fnames)), fnames, rotation=45, fontsize=20)\n",
    "plt.yticks(range(1), ['T{}'.format(i) for i in range(1)], fontsize=20)\n",
    "plt.xlabel('Bands and band related features', fontsize=20)\n",
    "plt.ylabel('Time frames', fontsize=20)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top') \n",
    "\n",
    "# cax = fig.add_axes([0.82, 0.125, 0.04, 0.755]) \n",
    "# plt.colorbar(im, cax=cax)\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "cb = fig.colorbar(im, ax=[ax], orientation='horizontal', pad=0.01, aspect=100)\n",
    "cb.ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictPatch(EOTask):\n",
    "    \"\"\"\n",
    "    Task to make model predictions on a patch. Provide the model and the feature, \n",
    "    and the output names of labels and scores (optional)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, features_feature, predicted_labels_name, predicted_scores_name=None):\n",
    "        self.model = model\n",
    "        self.features_feature = features_feature\n",
    "        self.predicted_labels_name = predicted_labels_name\n",
    "        self.predicted_scores_name = predicted_scores_name\n",
    "        \n",
    "    def execute(self, eopatch):\n",
    "        ftrs = eopatch[self.features_feature[0]][self.features_feature[1]]\n",
    "        \n",
    "        t, w, h, f = ftrs.shape\n",
    "        ftrs = ftrs.reshape(t * w * h, f)\n",
    "        \n",
    "        plabels = self.model.predict(ftrs)\n",
    "        plabels = plabels.reshape(t, w, h )\n",
    "        plabels = plabels[..., np.newaxis]\n",
    "        #eopatch.add_feature(FeatureType.MASK_TIMELESS, self.predicted_labels_name, plabels)\n",
    "        \n",
    "        if self.predicted_scores_name:\n",
    "            pscores = self.model.predict_proba(ftrs)\n",
    "            _, d = pscores.shape\n",
    "            pscores = pscores.reshape(w, h, d)\n",
    "            eopatch.add_feature(FeatureType.DATA_TIMELESS, self.predicted_scores_name, pscores)\n",
    "        \n",
    "        return plabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_patch = io_utils.load_exemplary_eopatch_from_file(file='../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2019_05-2019_10/',  patch_id=6, random_choice=True)\n",
    "eo_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK FOR PREDICTION\n",
    "predict_patch = PredictPatch(model, (FeatureType.DATA, 'DATASET_RAW_NDWI_NRB_19_NORM_SLOPE'), 'WATER_MASK_ST_025')\n",
    "\n",
    "predictions = []\n",
    "predictions.append(predict_patch.execute(eo_patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_timeless_mask_LANDSAT_8(eo_patch, band_idx=0, mask_acces_name='WATER_MASK_ST_025_COUNT' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_RGB_LANDSAT_8_image(eo_patch, datetime_idx=15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_RGB_MODIS_image(eo_patch, data_acces_name='MODIS_RAW_BANDS_DAY_0', datetime_idx=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_no = 15\n",
    "reference_patch = eo_patch.mask['WATER_MASK_ST_025'][patch_no]\n",
    "inspected_patch = predictions[0][patch_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_matrix(reference_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_matrix(inspected_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_matrix(eo_patch.data_timeless['DEM_RAW_LAYER'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_all_bands_in_data_acces_name(eo_patch, data_acces_name='DATASET_RAW_NDWI_NRB_19_NORM_SLOPE', datetime_idx=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  test patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to load the model and replace with your file, usually just correct the date\n",
    "#model_path = './NEW_model_20000_unbalanced_WATER_only_MODIS_test_7_fixed_lr_01_min_wat_50.pkl'\n",
    "#model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Load test eopatch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare EOPatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eopatches_filenames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eo_patch_filepath = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2019_05-2019_10/3473_maxcc_0.05_x-7_y-134'\n",
    "\n",
    "eo_patch_test = EOPatch.load(test_eo_patch_filepath) \n",
    "eo_patch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK FOR PREDICTION\n",
    "predict_patch = PredictPatch(model, (FeatureType.DATA, 'DATASET_RAW_NDWI_NRB_19_NORM_SLOPE'), 'WATER_MASK_ST_025')\n",
    "\n",
    "predictions_test = []\n",
    "predictions_test.append(predict_patch.execute(eo_patch_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_timeless_mask_LANDSAT_8(eo_patch_test, band_idx=0, mask_acces_name='WATER_MASK_ST_025_COUNT' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_RGB_LANDSAT_8_image(eo_patch_test, datetime_idx=15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_RGB_MODIS_image(eo_patch_test, data_acces_name='MODIS_RAW_BANDS_DAY_0', datetime_idx=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_no = 15\n",
    "reference_patch_test = eo_patch_test.mask['WATER_MASK_ST_025'][patch_no]\n",
    "inspected_patch_test = predictions_test[0][patch_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_matrix(reference_patch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_matrix(inspected_patch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_matrix(eo_patch_test.data_timeless['DEM_RAW_LAYER'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_matrix(eo_patch_test.data_timeless['DEM_SLOPE_LAYER'][1:-1,1:-1].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_features = eo_patch_test.mask_timeless['WATER_MASK_ST_025_COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_pictures_on_top_of_each_other(background_picture , mask, alpha):\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(background_picture.squeeze(), interpolation='none')\n",
    "    plt.imshow(mask.squeeze(), interpolation='none', alpha=alpha)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_two_pictures_on_top_of_each_other(reference_patch_test, inspected_patch_test, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeout: These model is similar as D5f i g and both of them can be applied to initial result production, this has better recall for water. - kind of better we have to compare it to the previous test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "\n",
    "dataset_name = 'dataset_2013_05-2019_10_sptl_smpl_20000_pr_patch_unbalanced_classes_0_1_min_25_ test_7_patches'\n",
    "\n",
    "with open('{}.pickle'.format(dataset_name), 'rb') as data:\n",
    "    dataset = pickle.load(data)\n",
    "    \n",
    "features_train_cmp = dataset[0]\n",
    "labels_train_cmp = dataset[1]\n",
    "features_test_cmp = dataset[2]\n",
    "labels_test_cmp = dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test labels\n",
    "print('TEST')\n",
    "plabels_test_cmp = model.predict(features_test_cmp)\n",
    "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_test_cmp, plabels_test_cmp)))\n",
    "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_test_cmp, plabels_test_cmp, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAIN')\n",
    "# predict the train labels\n",
    "plabels_train_cmp = model.predict(features_train_cmp)\n",
    "\n",
    "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_train_cmp, plabels_train_cmp)))\n",
    "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_train_cmp, plabels_train_cmp, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_water_cmp = np.count_nonzero(labels_test_cmp)\n",
    "predicted_water_cmp = np.count_nonzero(plabels_test_cmp)\n",
    "\n",
    "print('Water Test data size:',actual_water_cmp)\n",
    "\n",
    "tp_cmp = np.count_nonzero(np.logical_and(labels_test_cmp.squeeze(), plabels_test_cmp.squeeze()))\n",
    "print('Water True positive:', tp_cmp, 'and recall', 100* tp_cmp /actual_water_cmp, 'and precision:', tp_cmp /predicted_water_cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.unique(labels_test)\n",
    "print(class_labels)\n",
    "class_names = ['non-water', 'water']\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_scores = metrics.f1_score(labels_test_cmp, plabels_test_cmp, labels=class_labels, average=None)\n",
    "recall = metrics.recall_score(labels_test_cmp, plabels_test_cmp, labels=class_labels, average=None)\n",
    "precision = metrics.precision_score(labels_test_cmp, plabels_test_cmp, labels=class_labels, average=None) \n",
    "\n",
    "print('             Class              =  F1  | Recall | Precision')\n",
    "print('         --------------------------------------------------')\n",
    "for idx, lulctype in enumerate([class_names[idx] for idx in class_labels]):\n",
    "    print('         * {0:20s} = {1:2.1f}% |  {2:2.1f}%  | {3:2.1f}%'.format(lulctype, \n",
    "                                                                         f1_scores[idx] * 100, \n",
    "                                                                         recall[idx] * 100, \n",
    "                                                                         precision[idx] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old test dataset:\n",
    "\n",
    "#import pickle\n",
    "\n",
    "dataset_name = 'dataset_2013_05-2019_10_sptl_smpl_20000_pr_patch_unbalanced_classes_0_1_min_25_ test_7_patches'\n",
    "\n",
    "with open('{}.pickle'.format(dataset_name), 'rb') as data:\n",
    "    dataset = pickle.load(data)\n",
    "    \n",
    "features_train_cmp = dataset[0]\n",
    "labels_train_cmp = dataset[1]\n",
    "features_test_cmp = dataset[2]\n",
    "labels_test_cmp = dataset[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
