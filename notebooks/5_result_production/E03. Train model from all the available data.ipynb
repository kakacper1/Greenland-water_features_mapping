{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E03. Train model from all the available data\n",
    "#### 0. Load required libraries, site dependant constants and utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "# EOLearn libraries:\n",
    "from eolearn.core import EOTask, EOPatch, LinearWorkflow, LoadTask, SaveTask, FeatureType, EOExecutor\n",
    "from eolearn.core import OverwritePermission\n",
    "\n",
    "# Add to python path parent dictionary\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# load site dependant constants (HERE YOU CAN CHOOSE DIFFERENT LOCATION)\n",
    "from aoi_sites import upe_promice_area as site\n",
    "\n",
    "# load utility functions\n",
    "from utils import io_functions as io_utils\n",
    "from utils import plot_functions as plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load sampled eopatches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick dataset_name\n",
    "input_dataset_file_name = '_sptl_smpl_20000_pr_patch_blanced_only_wat_1_min_wat_50/'\n",
    "\n",
    "dataset_filepath_2013 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2013_05-2013_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2014 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2014_05-2014_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2015 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2015_05-2015_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2016 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2016_05-2016_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2017 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2017_05-2017_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2018 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2018_05-2018_10{}'.format(input_dataset_file_name)\n",
    "dataset_filepath_2019 = '../../data/EOPatches/LANDSAT_8/UPE_PROMICE/UTM_22N/2019_05-2019_10{}'.format(input_dataset_file_name)\n",
    "\n",
    "dataset_path_list = [dataset_filepath_2013,\n",
    "                dataset_filepath_2014,\n",
    "                dataset_filepath_2015,\n",
    "                dataset_filepath_2016,\n",
    "                dataset_filepath_2017,\n",
    "                dataset_filepath_2018,\n",
    "                dataset_filepath_2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eopatches= []\n",
    "train_eopatches_filenames = []\n",
    "\n",
    "for eopatches_filepath in dataset_path_list:\n",
    "\n",
    "    list_of_available_patches = io_utils.get_list_of_eopatches(eopatches_filepath)\n",
    "    list_in_chunks = io_utils.chunkIt(list_of_available_patches, 1 ) # number of chunks- 1 bc all can go\n",
    "    for chunk in list_in_chunks:\n",
    "        #print('Doing now following eopatches:', chunk )\n",
    "        for eopatch_name in chunk:\n",
    "            train_eopatches_filenames.append(eopatches_filepath+eopatch_name)\n",
    "            train_eopatches.append(EOPatch.load(eopatches_filepath+eopatch_name, lazy_loading=True))\n",
    "print(len(train_eopatches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. Fetch and organise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the train and test patch IDs\n",
    "\n",
    "# Set the features and the labels for train and test sets\n",
    "features_train = np.array([eopatch.data['DATASET_CLD_200_dil_6_str2_SAMPLED'] for eopatch in train_eopatches if eopatch.data['DATASET_CLD_200_dil_6_str2_SAMPLED'].size > 0])\n",
    "#features_train (number_of_patches,(time,width,height, bands))\n",
    "labels_train = np.array([eopatch.mask['WATER_MASK_ST_025_SAMPLED'] for eopatch in train_eopatches if eopatch.mask['WATER_MASK_ST_025_SAMPLED'].size > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to  (number_of_patches x time, width, height, bands)\n",
    "features_train_stacked = np.vstack(features_train)\n",
    "labels_train_stacked = np.vstack(labels_train)\n",
    "\n",
    "# get shape\n",
    "p_train_x_time, w, h, b = features_train_stacked.shape\n",
    "\n",
    "features_train = features_train_stacked.reshape(p_train_x_time * w * h, b)\n",
    "labels_train = labels_train_stacked.reshape(p_train_x_time * w * h, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3. Data statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Total observations:  37320000\n",
      "Total water count 7454798\n",
      "Percent of water feature among data: 0.19975342979635585\n"
     ]
    }
   ],
   "source": [
    "#to compare old data distribution (little less )\n",
    "\n",
    "print('TRAIN DATA:')\n",
    "tot_obs = np.size(labels_train)\n",
    "print('Total observations: ', tot_obs )\n",
    "\n",
    "tot_wat = np.count_nonzero(labels_train)\n",
    "print('Total water count', tot_wat )\n",
    "\n",
    "ratio_wat_vs_non_wat = tot_wat/ tot_obs\n",
    "print('Percent of water feature among data:', ratio_wat_vs_non_wat )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamil\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Kamil\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
       "               max_depth=-1, metric='binary_logloss', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set up training classes\n",
    "labels_unique = np.unique(labels_train)\n",
    "\n",
    "# Set up the model\n",
    "model = LGBMClassifier(boosting='gbdt',\n",
    "    objective='binary',\n",
    "    learning_rate=0.1,\n",
    "    metric='binary_logloss', #mae: mean absolute error mse: mean squared error\n",
    "    #class_weight= 'balanced' \n",
    "                       \n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(features_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./LGBMClassifier_model_20000_unbalanced_WATER_only_MODIS_test_0_fixed_lr_01_min_wat_50.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment to save the model\n",
    "model_base_name = 'LGBMClassifier_model_20000_unbalanced_WATER_only_MODIS_test_0_fixed_lr_01_min_wat_50'\n",
    "joblib.dump(model, './{}.pkl'.format(model_base_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  6. Validate model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "Classification accuracy 84.3%\n",
      "Classification F1-score 82.2%\n"
     ]
    }
   ],
   "source": [
    "# predict the train labels\n",
    "plabels_train = model.predict(features_train)\n",
    "print('TRAIN:')\n",
    "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_train, plabels_train)))\n",
    "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_train, plabels_train, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['non-water', 'water']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = np.unique(labels_train)\n",
    "print(class_labels)\n",
    "class_names = ['non-water', 'water']\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Class              =  F1  | Recall | Precision\n",
      "         --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         * non-water            = 90.7% |  96.3%  | 85.8%\n",
      "         * water                = 47.7% |  36.0%  | 70.9%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1_scores = metrics.f1_score(labels_train, plabels_train, labels=class_labels, average=None)\n",
    "recall = metrics.recall_score(labels_train, plabels_train, labels=class_labels, average=None)\n",
    "precision = metrics.precision_score(labels_train, plabels_train, labels=class_labels, average=None) \n",
    "\n",
    "print('             Class              =  F1  | Recall | Precision')\n",
    "print('         --------------------------------------------------')\n",
    "for idx, lulctype in enumerate([class_names[idx] for idx in class_labels]):\n",
    "    print('         * {0:20s} = {1:2.1f}% |  {2:2.1f}%  | {3:2.1f}%'.format(lulctype, \n",
    "                                                                         f1_scores[idx] * 100, \n",
    "                                                                         recall[idx] * 100, \n",
    "                                                                         precision[idx] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TAKEAWAY: \n",
    "\n",
    "Of course these results are biased bc done on top of training data. Yet it is nice to see that I gained 2 % becasue we dont have test data. More training data is can elevate the result. Now this model will be used to produce masks for MODIS 2000 - 2019 :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
